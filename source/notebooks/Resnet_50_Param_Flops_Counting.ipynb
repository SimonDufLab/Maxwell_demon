{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5O1UdsY202_"
      },
      "source": [
        "### Adapted from RiGL paper notebook:\n",
        "https://github.com/google-research/rigl/blob/master/rigl/imagenet_resnet/colabs/Resnet_50_Param_Flops_Counting.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5p1fkA3rgL_"
      },
      "outputs": [],
      "source": [
        "# Download the official ResNet50 implementation and other libraries.\n",
        "# the ResNet50 module s.t. we can use the model builders for our counting.\n",
        "%%bash\n",
        "test -d tpu || git clone https://github.com/tensorflow/tpu tpu && mv tpu/models/experimental/resnet50_keras ./\n",
        "test -d rigl || git clone https://github.com/google-research/rigl rigl_repo && mv rigl_repo/rigl ./\n",
        "test -d gresearch || git clone https://github.com/google-research/google-research google_research\n",
        "pip install aim==3.17"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf /content/imagenet_exps.tar.xz"
      ],
      "metadata": {
        "id": "7X_XK7nUgObs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmr3djWe1rKj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google_research.micronet_challenge import counting\n",
        "from resnet50_keras import resnet_model as resnet_keras\n",
        "from rigl import sparse_utils\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYm9k-Q47PXe"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "model = resnet_keras.ResNet50(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNS1s5Wm7U8-"
      },
      "outputs": [],
      "source": [
        "masked_layers = []\n",
        "for layer in model.layers:\n",
        "  if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "    masked_layers.append(layer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtD03TrBSDzV"
      },
      "outputs": [],
      "source": [
        "PARAM_SIZE=32 # bits\n",
        "import functools\n",
        "get_stats = functools.partial(\n",
        "    sparse_utils.get_stats, first_layer_name='conv1', last_layer_name='fc1000',\n",
        "    param_size=PARAM_SIZE)\n",
        "def print_stats(masked_layers, default_sparsity=0.8, method='erdos_renyi',\n",
        "                custom_sparsities={}, is_debug=False, width=1., **kwargs):\n",
        "  print('Method: %s, Sparsity: %f' % (method, default_sparsity))\n",
        "  total_flops, total_param_bits, sparsity = get_stats(\n",
        "      masked_layers, default_sparsity=default_sparsity, method=method,\n",
        "      custom_sparsities=custom_sparsities, is_debug=is_debug, width=width, **kwargs)\n",
        "  print('Total Flops: %.3f MFlops' % (total_flops/1e6))\n",
        "  print('Total Size: %.3f Mbytes' % (total_param_bits/8e6))\n",
        "  print('Real Sparsity: %.3f' % (sparsity))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading sparsity from aim"
      ],
      "metadata": {
        "id": "aGiIOs6DN6I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 50 layers + 4 projection layers at the beginning of every block (for the skip connection)\n",
        "\n",
        "resnet_layers=['conv1/kernel:0',\n",
        "'res2a_branch2a/kernel:0',\n",
        "'res2a_branch2b/kernel:0',\n",
        "'res2a_branch2c/kernel:0',\n",
        "'res2a_branch1/kernel:0',\n",
        "'res2b_branch2a/kernel:0',\n",
        "'res2b_branch2b/kernel:0',\n",
        "'res2b_branch2c/kernel:0',\n",
        "'res2c_branch2a/kernel:0',\n",
        "'res2c_branch2b/kernel:0',\n",
        "'res2c_branch2c/kernel:0',\n",
        "'res3a_branch2a/kernel:0',\n",
        "'res3a_branch2b/kernel:0',\n",
        "'res3a_branch2c/kernel:0',\n",
        "'res3a_branch1/kernel:0',\n",
        "'res3b_branch2a/kernel:0',\n",
        "'res3b_branch2b/kernel:0',\n",
        "'res3b_branch2c/kernel:0',\n",
        "'res3c_branch2a/kernel:0',\n",
        "'res3c_branch2b/kernel:0',\n",
        "'res3c_branch2c/kernel:0',\n",
        "'res3d_branch2a/kernel:0',\n",
        "'res3d_branch2b/kernel:0',\n",
        "'res3d_branch2c/kernel:0',\n",
        "'res4a_branch2a/kernel:0',\n",
        "'res4a_branch2b/kernel:0',\n",
        "'res4a_branch2c/kernel:0',\n",
        "'res4a_branch1/kernel:0',\n",
        "'res4b_branch2a/kernel:0',\n",
        "'res4b_branch2b/kernel:0',\n",
        "'res4b_branch2c/kernel:0',\n",
        "'res4c_branch2a/kernel:0',\n",
        "'res4c_branch2b/kernel:0',\n",
        "'res4c_branch2c/kernel:0',\n",
        "'res4d_branch2a/kernel:0',\n",
        "'res4d_branch2b/kernel:0',\n",
        "'res4d_branch2c/kernel:0',\n",
        "'res4e_branch2a/kernel:0',\n",
        "'res4e_branch2b/kernel:0',\n",
        "'res4e_branch2c/kernel:0',\n",
        "'res4f_branch2a/kernel:0',\n",
        "'res4f_branch2b/kernel:0',\n",
        "'res4f_branch2c/kernel:0',\n",
        "'res5a_branch2a/kernel:0',\n",
        "'res5a_branch2b/kernel:0',\n",
        "'res5a_branch2c/kernel:0',\n",
        "'res5a_branch1/kernel:0',\n",
        "'res5b_branch2a/kernel:0',\n",
        "'res5b_branch2b/kernel:0',\n",
        "'res5b_branch2c/kernel:0',\n",
        "'res5c_branch2a/kernel:0',\n",
        "'res5c_branch2b/kernel:0',\n",
        "'res5c_branch2c/kernel:0',\n",
        "'fc1000/kernel:0']\n",
        "\n",
        "print(len(resnet_layers))"
      ],
      "metadata": {
        "id": "enaXJUXzN-w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract layer sparsity from aim run\n",
        "import aim\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "run_hash = '9eaf384e01d64dac80a7d9f6'\n",
        "# data=[]\n",
        "# for i in range(49):\n",
        "query = f\"'Live neurons in layer' in metric.name and '; whole training dataset' in metric.name and run.hash=='{run_hash}'\"\n",
        "print(query)\n",
        "df = aim.Repo(\"/content/imagenet_exps\").query_metrics(query).dataframe()\n",
        "df.head(10)\n",
        "\n",
        "# data.append(aim.Repo(\"/content/imagenet_exps\").query_metrics(query).dataframe())\n",
        "\n",
        "# df = pd.concat(data, ignore_index=True)"
      ],
      "metadata": {
        "id": "HrgtyL6DyrEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add neuron ratio column (which will be equal to params ratio for conv layers)\n",
        "df[\"sparsity\"] = 0\n",
        "# print(df[\"metric.name\"].unique())\n",
        "for layer in df[\"metric.name\"].unique():\n",
        "  neuron_in_layer = df[df['metric.name']==layer]\n",
        "  neuron_in_layer = neuron_in_layer[neuron_in_layer['step']==0][\"value\"].iloc[0]\n",
        "  # print(neuron_in_layer)\n",
        "  df.loc[df['metric.name'] == layer, \"sparsity\"] = 1 - df.loc[df['metric.name'] == layer, \"value\"] / neuron_in_layer\n",
        "\n",
        "# df.tail(10)\n",
        "\n",
        "# Now a function to map layer to specific sparsity at any give step\n",
        "def retrieve_sparsity(step):\n",
        "  j = 0 # True index, taking into account the skip (with projections) layers\n",
        "  sparsities = []\n",
        "  for i, layer_name in enumerate(resnet_layers[:-1]):\n",
        "    if \"branch1\" in layer_name:\n",
        "      j += 1  # To handle skip layers\n",
        "    col_name = f\"Live neurons in layer {i-j}; whole training dataset\"\n",
        "    sparsities.append(df[(df['metric.name'] == col_name) & (df['step'] == step)][\"sparsity\"].iloc[0])\n",
        "    #print(sparsities)\n",
        "  sparsities.append(0) # We never prune the fully connected layers with structured pruning\n",
        "  return dict(zip(resnet_layers, sparsities))\n",
        "\n",
        "print(retrieve_sparsity(0))\n",
        "print(retrieve_sparsity(500000))"
      ],
      "metadata": {
        "id": "UxoXn5ef84Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_2kH9dsrUqu"
      },
      "source": [
        "# Pruning FLOPs\n",
        "We calculate theoratical FLOPs for pruning, which means we will start counting sparse FLOPs when the pruning starts."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide training and inference flops for the run precised by the aim hash above\n",
        "\n",
        "pruning_freq = 5000\n",
        "batch_size = 256\n",
        "total_steps = 500456\n",
        "\n",
        "training_flops=0\n",
        "seq_flops = []\n",
        "for step in range(0, total_steps, pruning_freq):\n",
        "  step_sparsities=retrieve_sparsity(step)\n",
        "  c_flops, _, _ = get_stats(\n",
        "      masked_layers, default_sparsity=0.0, method='random', custom_sparsities=step_sparsities)\n",
        "  seq_flops.append(c_flops)\n",
        "  if step < (total_steps//pruning_freq)*pruning_freq:\n",
        "    training_flops += c_flops * 3 * pruning_freq * batch_size\n",
        "    # print(step)\n",
        "# Get the tail:\n",
        "training_flops += c_flops * 3 * (total_steps-step) * batch_size\n",
        "print(f\"training flops:{training_flops}\")\n",
        "print(f\"inference flops:{c_flops}\")\n",
        "#print(seq_flops)"
      ],
      "metadata": {
        "id": "rbOEJFkHLVZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHmbXdMyT2c8"
      },
      "outputs": [],
      "source": [
        "# From RiGL notebook; used to calculute dense network flops\n",
        "\n",
        "p_start, p_end, p_freq = 10000,25000,1000\n",
        "target_sparsity = 0.8\n",
        "total_flops = []\n",
        "for i in range(0,32001,1000):\n",
        "  if i < p_start:\n",
        "    sparsity = 0.\n",
        "  elif p_end < i:\n",
        "    sparsity = target_sparsity\n",
        "  else:\n",
        "    sparsity = (1-(1-(i-p_start)/float(p_end-p_start))**3)*target_sparsity\n",
        "  # print(i, sparsity)\n",
        "  c_flops, _, _ = get_stats(\n",
        "      masked_layers, default_sparsity=sparsity, method='random', custom_sparsities={'conv1/kernel:0':0, 'fc1000/kernel:0':0.0})\n",
        "  # print(i, c_flops, sparsity)\n",
        "  total_flops.append(c_flops)\n",
        "avg_flops = sum(total_flops) / len(total_flops)\n",
        "print('Average Flops: ', avg_flops, avg_flops/total_flops[0])\n",
        "# print(total_flops)\n",
        "print('Training Flops: ', total_flops[0]* 3 * 1281167 * 100)\n",
        "print('Inference Flops: ', total_flops[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}